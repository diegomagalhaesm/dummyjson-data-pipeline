# DummyJSON Data Pipeline â€“ ETL com Python e PostgreSQL

Projeto de pipeline de dados completo (ETL) que consome dados dinÃ¢micos de uma API pÃºblica, realiza tratamento e normalizaÃ§Ã£o e carrega os dados em um banco PostgreSQL para anÃ¡lise posterior e construÃ§Ã£o de dashboards.

Este projeto foi desenvolvido com foco em boas prÃ¡ticas de Engenharia de Dados JÃºnior e AnÃ¡lise de Dados.

---

## ğŸ“Œ Objetivo

Demonstrar, na prÃ¡tica, a construÃ§Ã£o de um pipeline de dados moderno:

* ExtraÃ§Ã£o de dados via API REST
* TransformaÃ§Ã£o e limpeza com Python
* Carga estruturada em banco relacional
* OrganizaÃ§Ã£o modular do cÃ³digo
* Uso de variÃ¡veis de ambiente
* PreparaÃ§Ã£o para anÃ¡lise e BI

---

## ğŸ§± Arquitetura do Pipeline

[![](https://mermaid.ink/img/pako:eNo9kU1PwkAQhv_KZk6aFOx3uz2YAMUEg1rFky2Htbu0RHaXTLdBJPx324LOaWaf5905zAlKzQUksNnpQ1kzNGT5VijS1SSfZAuStlIeH1cvz2syGt2TaT7_NshKQ0YkO5paq_XFng54lr8jU81Go-wFpjhrrsJsENJ8qRnv2Op1OdmVtZDHK08HPs9vMt2YCkUn3F7RfEAPeaYPAsl0Qe5Iypr6UzPkzRosqHDLITHYCgukQMn6EU59ugDTLREFJF3LGX4VUKhzl9kz9aG1_Iuhbqsakg3bNd3U7jkzIt2yCpn8f0WhuMCZbpWBxAns4RNITvANiRuO_SAMXUrdIHKjILLg2EvxOIpp6NiO78V-aHtnC36GtfaY-h6NaRD51KauY3sWCL41Gp8uFxkOc_4FWSJ8Ug?type=png)](https://mermaid.live/edit#pako:eNo9kU1PwkAQhv_KZk6aFOx3uz2YAMUEg1rFky2Htbu0RHaXTLdBJPx324LOaWaf5905zAlKzQUksNnpQ1kzNGT5VijS1SSfZAuStlIeH1cvz2syGt2TaT7_NshKQ0YkO5paq_XFng54lr8jU81Go-wFpjhrrsJsENJ8qRnv2Op1OdmVtZDHK08HPs9vMt2YCkUn3F7RfEAPeaYPAsl0Qe5Iypr6UzPkzRosqHDLITHYCgukQMn6EU59ugDTLREFJF3LGX4VUKhzl9kz9aG1_Iuhbqsakg3bNd3U7jkzIt2yCpn8f0WhuMCZbpWBxAns4RNITvANiRuO_SAMXUrdIHKjILLg2EvxOIpp6NiO78V-aHtnC36GtfaY-h6NaRD51KauY3sWCL41Gp8uFxkOc_4FWSJ8Ug)
---

## ğŸ›  Tecnologias utilizadas

* Python 3.14+
* Requests
* Pandas
* SQLAlchemy
* PostgreSQL
* Power BI (dashboards)
* Git & GitHub

---

## ğŸ“ Estrutura do projeto

```
dummyjson-data-pipeline/
â”‚
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ extract.py
â”‚   â”œâ”€â”€ transform.py
â”‚   â””â”€â”€ load.py
â”‚
â”œâ”€â”€ db/
â”‚   â””â”€â”€ schema.sql
â”‚
â”œâ”€â”€ logs/
â”œâ”€â”€ dashboards/
â”œâ”€â”€ main.py
â”œâ”€â”€ config.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âš™ï¸ ConfiguraÃ§Ã£o do ambiente

### 1. Clonar o projeto

```bash
git clone https://github.com/seu-usuario/dummyjson-data-pipeline.git
cd dummyjson-data-pipeline
```

### 2. Criar ambiente virtual

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

### 3. Instalar dependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Configurar banco de dados

Criar banco no PostgreSQL:

```sql
CREATE DATABASE dummy_pipeline;
```

Executar o script:

```sql
\i db/schema.sql
```

### 5. Configurar conexÃ£o

No arquivo `config.py`:

```python
DB_URL = "postgresql://usuario:senha@localhost:5432/dummy_pipeline"
```

---

## â–¶ï¸ Executar pipeline

```bash
python main.py
```

---

## ğŸ“Š Dashboards

Os dashboards sÃ£o desenvolvidos no Power BI a partir da tabela `fact_orders`.

Indicadores sugeridos:

* Total de pedidos
* Receita total
* Ticket mÃ©dio
* Pedidos por status
* Pedidos por data
* Top clientes
* Top produtos

Arquivo PBIX armazenado na pasta:

```
dashboards/
```

---

## ğŸ§  Conceitos aplicados

* ETL (Extract, Transform, Load)
* Modelagem analÃ­tica
* NormalizaÃ§Ã£o de dados
* Qualidade de dados
* Pipelines
* SQL
* Versionamento
* Boas prÃ¡ticas de projeto

---

## ğŸš€ PrÃ³ximos aprimoramentos

* Incremental Load
* Logs estruturados
* DockerizaÃ§Ã£o
* OrquestraÃ§Ã£o (Airflow / Prefect)
* Testes automatizados
* CI/CD

---

## ğŸ‘¤ Autor

Diego MagalhÃ£es Menezes
Analista de Dados em transiÃ§Ã£o | SQL | Python | BI

LinkedIn: [https://www.linkedin.com/in/diegomagalhaesmenezes/](https://www.linkedin.com/in/diegomagalhaesmenezes/)

---

## ğŸ“„ LicenÃ§a

Projeto livre para fins educacionais e portfÃ³lio.
